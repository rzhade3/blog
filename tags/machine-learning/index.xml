<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>machine learning on Blog</title><link>https://blog.zhade.dev/tags/machine-learning/</link><description>Recent content in machine learning on Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 03 Apr 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.zhade.dev/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Introduction to Adversarial AI</title><link>https://blog.zhade.dev/posts/2023-04-03-intro-adversarial-ai/</link><pubDate>Mon, 03 Apr 2023 00:00:00 +0000</pubDate><guid>https://blog.zhade.dev/posts/2023-04-03-intro-adversarial-ai/</guid><description>The following is a transcription of a talk I&amp;rsquo;ve given internally at GitHub. The talk, and slides, are about the basics of adversarial AI, and how it can be used to attack machine learning models.
Slides
Transcript How do Machine Learning Systems work? For the purposes of this talk/ blog post, weâ€™re not going to go too in depth into the technical details of machine learning algorithms. However, from a security perspective, it is important to note the flow of data.</description></item></channel></rss>